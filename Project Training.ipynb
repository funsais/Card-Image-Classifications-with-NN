{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd_train = pd.read_csv('Training Data.csv')\n",
    "dd_test = pd.read_csv('Testing Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_train = dd_train.values[:,1:129].astype(np.float64)\n",
    "in_train = scale(in_train, axis = 1)\n",
    "out_train = dd_train.label.astype('category')\n",
    "out_train = pd.get_dummies( out_train ).values.astype(np.float64)\n",
    "in_valid = dd_test.values[:,1:129].astype(np.float64)\n",
    "in_valid = scale(in_valid, axis = 1)\n",
    "out_valid = dd_test.label.astype('category')\n",
    "out_valid = pd.get_dummies( out_valid ).values.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_train = in_train.shape[0]\n",
    "N_feat = in_train.shape[1]\n",
    "N_cat = out_train.shape[1]\n",
    "N_valid = in_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "EPOCHS  = 100        # number of training epochs\n",
    "N_nodes  = 128        # nodes in hidden layer\n",
    "ALPHA   = 0          # regularization parameter\n",
    "BS      = 2000         # batch size\n",
    "STD     = 0.1        # weight initialization standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = tf.placeholder( tf.float32, [BS, N_feat] )\n",
    "y_train = tf.placeholder( tf.float32, [BS, N_cat] )\n",
    "\n",
    "x_train_f = tf.constant( in_train , tf.float32, [N_train,N_feat])\n",
    "y_train_f = tf.constant( out_train , tf.float32, [N_train,N_cat])\n",
    "\n",
    "x_valid = tf.constant( in_valid , tf.float32, [N_valid , N_feat] )\n",
    "y_valid = tf.constant( out_valid, tf.float32, [N_valid, N_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w1 = tf.Variable( tf.truncated_normal( [N_feat,N_nodes], stddev = STD, seed=0))\n",
    "b1 = tf.Variable( tf.truncated_normal( [1,N_nodes], stddev = STD, seed=0))\n",
    "\n",
    "y1_train = tf.nn.relu( tf.matmul(x_train,w1) + b1 )\n",
    "y1_train_f = tf.nn.relu( tf.matmul(x_train_f,w1) + b1 )\n",
    "y1_valid = tf.nn.relu( tf.matmul( x_valid, w1) + b1 )\n",
    "\n",
    "w2 = tf.Variable( tf.truncated_normal( [N_nodes,N_cat], stddev = STD, seed=0))\n",
    "b2 = tf.Variable( tf.truncated_normal( [1,N_cat], stddev = STD, seed=0))\n",
    "\n",
    "logits_train = tf.matmul(y1_train,w2) + b2\n",
    "logits_train_f = tf.matmul(y1_train_f,w2) + b2\n",
    "logits_valid = tf.matmul(y1_valid,w2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CE = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits( \n",
    "        logits_train, y_train) )\n",
    "L2 = ALPHA*(tf.nn.l2_loss(w1) + tf.nn.l2_loss(b1) + \\\n",
    "               tf.nn.l2_loss(w2) + tf.nn.l2_loss(b2))\n",
    "CE_train_f = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits_train_f, y_train_f) )\n",
    "CE_valid = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits_valid, y_valid) )\n",
    "\n",
    "y_train_p = tf.nn.softmax( logits_train )\n",
    "y_train_fp = tf.nn.softmax( logits_train_f )\n",
    "y_valid_p = tf.nn.softmax( logits_valid )\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer().minimize(CE+L2)\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs =100, Training Set Size =2000, Nodes =   128, Alpha = 0.0000, Batch Size = 2000, STD = 0.100\n",
      "\n",
      "                          cross-entropy              error-rate\n",
      "          epoch    training  validation    training  validation          L2  time (min)\n",
      "    100       0     2.43549     2.43479       0.918       0.911       0.000         0.0\n",
      "    100      10     0.80790     0.81041       0.004       0.005       0.000         0.0\n",
      "    100      20     0.18845     0.18972       0.000       0.000       0.000         0.0\n",
      "    100      30     0.05470     0.05497       0.000       0.000       0.000         0.0\n",
      "    100      40     0.02493     0.02501       0.000       0.000       0.000         0.0\n",
      "    100      50     0.01548     0.01549       0.000       0.000       0.000         0.0\n",
      "    100      60     0.01143     0.01141       0.000       0.000       0.000         0.0\n",
      "    100      70     0.00922     0.00919       0.000       0.000       0.000         0.0\n",
      "    100      80     0.00778     0.00775       0.000       0.000       0.000         0.0\n",
      "    100      90     0.00673     0.00670       0.000       0.000       0.000         0.0\n",
      "    100     100     0.00590     0.00588       0.000       0.000       0.000         0.0\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "np.random.seed(0)\n",
    "\n",
    "print( 'Epochs =%3d, Training Set Size =%4d, Nodes = %5d, Alpha = %3.4f, Batch Size = %4d, STD = %5.3f' %\n",
    "      (EPOCHS, N_train, N_nodes, ALPHA, BS, STD))\n",
    "print()\n",
    "print('%15s%24s%24s' % (' ','cross-entropy','error-rate'))\n",
    "print('%15s%12s%12s%12s%12s%12s%12s' % \n",
    "      ('epoch','training','validation','training','validation','L2','time (min)'))\n",
    "for i in range(EPOCHS+1): # For every Epoch\n",
    "    ran = np.random.permutation(N_train) # Order the data\n",
    "    reran = np.reshape( ran, [ int(N_train/BS) ,BS] ) #Reshape ordering as a matrix\n",
    "    for j in range( int(N_train/BS) ): # For every batch\n",
    "        mini = reran[j,:].astype(int) # Find the batch indices\n",
    "        x_batch = in_train[mini,:] # Call the batch features\n",
    "        y_batch = out_train[mini] # Call the batch labels\n",
    "        # Do a step with a batch\n",
    "        sess.run([optimizer],feed_dict = {x_train:x_batch, y_train:y_batch})\n",
    "    if (i % int(EPOCHS/10)) == 0:\n",
    "        ( ce_train, ce_valid, out_train_pf, out_valid_p, l2 ) = \\\n",
    "        sess.run( [CE_train_f, CE_valid, y_train_fp, y_valid_p,L2])\n",
    "        err_train = 1-accuracy_score( out_train.argmax(axis=1), \n",
    "                                   out_train_pf.argmax(axis=1))\n",
    "        err_valid  = 1-accuracy_score( out_valid.argmax(axis=1),\n",
    "                                    out_valid_p.argmax(axis=1))\n",
    "        t = (time.time() - t0)/60\n",
    "        print('%7d %7d%12.5f%12.5f%12.3f%12.3f%12.3f%12.1f' % \n",
    "              (EPOCHS,i,ce_train,ce_valid,err_train,err_valid,l2,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
